{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T06:37:38.018175Z","iopub.status.busy":"2023-12-09T06:37:38.017871Z","iopub.status.idle":"2023-12-09T06:37:40.994173Z","shell.execute_reply":"2023-12-09T06:37:40.993029Z","shell.execute_reply.started":"2023-12-09T06:37:38.018146Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(30000, 13, 3027)\n"]}],"source":["import re\n","\n","\n","lines = open('../input/chatbot-data/cornell movie-dialogs corpus/movie_lines.txt', encoding='utf-8',\n","             errors='ignore').read().split('\\n')\n","\n","convers = open('../input/chatbot-data/cornell movie-dialogs corpus/movie_conversations.txt', encoding='utf-8',\n","             errors='ignore').read().split('\\n')\n","\n","\n","exchn = []\n","for conver in convers:\n","    exchn.append(conver.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \" \").replace(\",\",\"\").split())\n","\n","diag = {}\n","for line in lines:\n","    diag[line.split(' +++$+++ ')[0]] = line.split(' +++$+++ ')[-1]\n","\n","## delete\n","del(lines, convers, conver, line)\n","\n","questions = []\n","answers = []\n","\n","for conver in exchn:\n","    for i in range(len(conver) - 1):\n","        questions.append(diag[conver[i]])\n","        answers.append(diag[conver[i+1]])\n","\n","## delete\n","del(diag, exchn, conver, i)\n","\n","\n","\n","\n","sorted_ques = []\n","sorted_ans = []\n","for i in range(len(questions)):\n","    if len(questions[i]) < 13:\n","        sorted_ques.append(questions[i])\n","        sorted_ans.append(answers[i])\n","\n","\n","\n","def clean_text(txt):\n","    txt = txt.lower()\n","    txt = re.sub(r\"i'm\", \"i am\", txt)\n","    txt = re.sub(r\"he's\", \"he is\", txt)\n","    txt = re.sub(r\"she's\", \"she is\", txt)\n","    txt = re.sub(r\"that's\", \"that is\", txt)\n","    txt = re.sub(r\"what's\", \"what is\", txt)\n","    txt = re.sub(r\"where's\", \"where is\", txt)\n","    txt = re.sub(r\"\\'ll\", \" will\", txt)\n","    txt = re.sub(r\"\\'ve\", \" have\", txt)\n","    txt = re.sub(r\"\\'re\", \" are\", txt)\n","    txt = re.sub(r\"\\'d\", \" would\", txt)\n","    txt = re.sub(r\"won't\", \"will not\", txt)\n","    txt = re.sub(r\"can't\", \"can not\", txt)\n","    txt = re.sub(r\"[^\\w\\s]\", \"\", txt)\n","    return txt\n","\n","clean_ques = []\n","clean_ans = []\n","\n","for line in sorted_ques:\n","    clean_ques.append(clean_text(line))\n","        \n","for line in sorted_ans:\n","    clean_ans.append(clean_text(line))\n","\n","\n","\n","## delete\n","del(answers, questions, line)\n","\n","\n","\n","for i in range(len(clean_ans)):\n","    clean_ans[i] = ' '.join(clean_ans[i].split()[:11])\n","\n","\n","\n","\n","\n","del(sorted_ans, sorted_ques)\n","\n","\n","## trimming\n","clean_ans=clean_ans[:30000]\n","clean_ques=clean_ques[:30000]\n","## delete\n","\n","\n","###  count occurences ###\n","word2count = {}\n","\n","for line in clean_ques:\n","    for word in line.split():\n","        if word not in word2count:\n","            word2count[word] = 1\n","        else:\n","            word2count[word] += 1\n","for line in clean_ans:\n","    for word in line.split():\n","        if word not in word2count:\n","            word2count[word] = 1\n","        else:\n","            word2count[word] += 1\n","\n","## delete\n","del(word, line)\n","\n","\n","###  remove less frequent ###\n","thresh = 5\n","\n","vocab = {}\n","word_num = 0\n","for word, count in word2count.items():\n","    if count >= thresh:\n","        vocab[word] = word_num\n","        word_num += 1\n","        \n","## delete\n","del(word2count, word, count, thresh)       \n","del(word_num)        \n","\n","\n","\n","for i in range(len(clean_ans)):\n","    clean_ans[i] = '<SOS> ' + clean_ans[i] + ' <EOS>'\n","\n","\n","\n","tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n","x = len(vocab)\n","for token in tokens:\n","    vocab[token] = x\n","    x += 1\n","    \n","    \n","\n","vocab['cameron'] = vocab['<PAD>']\n","vocab['<PAD>'] = 0\n","\n","## delete\n","del(token, tokens) \n","del(x)\n","\n","### inv answers dict ###\n","inv_vocab = {w:v for v, w in vocab.items()}\n","\n","\n","\n","## delete\n","del(i)\n","\n","\n","\n","encoder_inp = []\n","for line in clean_ques:\n","    lst = []\n","    for word in line.split():\n","        if word not in vocab:\n","            lst.append(vocab['<OUT>'])\n","        else:\n","            lst.append(vocab[word])\n","        \n","    encoder_inp.append(lst)\n","\n","decoder_inp = []\n","for line in clean_ans:\n","    lst = []\n","    for word in line.split():\n","        if word not in vocab:\n","            lst.append(vocab['<OUT>'])\n","        else:\n","            lst.append(vocab[word])        \n","    decoder_inp.append(lst)\n","\n","### delete\n","del(clean_ans, clean_ques, line, lst, word)\n","\n","\n","\n","\n","\n","\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","encoder_inp = pad_sequences(encoder_inp, 13, padding='post', truncating='post')\n","decoder_inp = pad_sequences(decoder_inp, 13, padding='post', truncating='post')\n","\n","\n","\n","\n","decoder_final_output = []\n","for i in decoder_inp:\n","    decoder_final_output.append(i[1:]) \n","\n","decoder_final_output = pad_sequences(decoder_final_output, 13, padding='post', truncating='post')\n","\n","\n","del(i)\n","\n","from tensorflow.keras.utils import to_categorical\n","decoder_final_output = to_categorical(decoder_final_output, len(vocab))\n","\n","\n","\n","print(decoder_final_output.shape)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T06:37:58.809181Z","iopub.status.busy":"2023-12-09T06:37:58.808814Z","iopub.status.idle":"2023-12-09T07:02:33.367168Z","shell.execute_reply":"2023-12-09T07:02:33.366167Z","shell.execute_reply.started":"2023-12-09T06:37:58.809135Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","938/938 [==============================] - 98s 104ms/step - loss: 3.1058 - acc: 0.4937\n","Epoch 2/15\n","938/938 [==============================] - 96s 102ms/step - loss: 2.7452 - acc: 0.5317\n","Epoch 3/15\n","938/938 [==============================] - 96s 102ms/step - loss: 2.6121 - acc: 0.5420\n","Epoch 4/15\n","938/938 [==============================] - 97s 104ms/step - loss: 2.5377 - acc: 0.5465\n","Epoch 5/15\n","938/938 [==============================] - 97s 104ms/step - loss: 2.4803 - acc: 0.5506\n","Epoch 6/15\n","938/938 [==============================] - 96s 102ms/step - loss: 2.4311 - acc: 0.5530\n","Epoch 7/15\n","938/938 [==============================] - 97s 104ms/step - loss: 2.3856 - acc: 0.5555\n","Epoch 8/15\n","938/938 [==============================] - 97s 103ms/step - loss: 2.3413 - acc: 0.5578\n","Epoch 9/15\n","938/938 [==============================] - 96s 103ms/step - loss: 2.2972 - acc: 0.5598\n","Epoch 10/15\n","938/938 [==============================] - 96s 103ms/step - loss: 2.2548 - acc: 0.5618\n","Epoch 11/15\n","938/938 [==============================] - 99s 105ms/step - loss: 2.2128 - acc: 0.5640\n","Epoch 12/15\n","938/938 [==============================] - 100s 106ms/step - loss: 2.1697 - acc: 0.5661\n","Epoch 13/15\n","938/938 [==============================] - 100s 107ms/step - loss: 2.1281 - acc: 0.5689\n","Epoch 14/15\n","938/938 [==============================] - 100s 107ms/step - loss: 2.0865 - acc: 0.5722\n","Epoch 15/15\n","938/938 [==============================] - 102s 109ms/step - loss: 2.0473 - acc: 0.5755\n"]},{"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x792d0219ded0>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["\n","\n","\n","\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Embedding, LSTM, Input\n","\n","\n","enc_inp = Input(shape=(13, ))\n","dec_inp = Input(shape=(13, ))\n","\n","\n","VOCAB_SIZE = len(vocab)\n","embed = Embedding(VOCAB_SIZE+1, output_dim=50, \n","                  input_length=13,\n","                  trainable=True                  \n","                  )\n","\n","\n","enc_embed = embed(enc_inp)\n","enc_lstm = LSTM(400, return_sequences=True, return_state=True)\n","enc_op, h, c = enc_lstm(enc_embed)\n","enc_states = [h, c]\n","\n","\n","\n","dec_embed = embed(dec_inp)\n","dec_lstm = LSTM(400, return_sequences=True, return_state=True)\n","dec_op, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n","\n","dense = Dense(VOCAB_SIZE, activation='softmax')\n","\n","dense_op = dense(dec_op)\n","\n","model = Model([enc_inp, dec_inp], dense_op)\n","\n","\n","\n","\n","model.compile(loss='categorical_crossentropy',metrics=['acc'],optimizer='adam')\n","\n","model.fit([encoder_inp, decoder_inp],decoder_final_output,epochs=15)\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T07:04:10.212827Z","iopub.status.busy":"2023-12-09T07:04:10.212331Z","iopub.status.idle":"2023-12-09T07:54:39.416691Z","shell.execute_reply":"2023-12-09T07:54:39.415752Z","shell.execute_reply.started":"2023-12-09T07:04:10.212793Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","938/938 [==============================] - 99s 105ms/step - loss: 2.0096 - acc: 0.5791\n","Epoch 2/30\n","938/938 [==============================] - 100s 107ms/step - loss: 1.9723 - acc: 0.5833\n","Epoch 3/30\n","938/938 [==============================] - 101s 107ms/step - loss: 1.9368 - acc: 0.5878\n","Epoch 4/30\n","938/938 [==============================] - 101s 108ms/step - loss: 1.9021 - acc: 0.5919\n","Epoch 5/30\n","938/938 [==============================] - 100s 106ms/step - loss: 1.8687 - acc: 0.5964\n","Epoch 6/30\n","938/938 [==============================] - 100s 106ms/step - loss: 1.8355 - acc: 0.6014\n","Epoch 7/30\n","938/938 [==============================] - 100s 106ms/step - loss: 1.8034 - acc: 0.6059\n","Epoch 8/30\n","938/938 [==============================] - 100s 106ms/step - loss: 1.7728 - acc: 0.6111\n","Epoch 9/30\n","938/938 [==============================] - 101s 108ms/step - loss: 1.7420 - acc: 0.6160\n","Epoch 10/30\n","938/938 [==============================] - 102s 109ms/step - loss: 1.7126 - acc: 0.6216\n","Epoch 11/30\n","938/938 [==============================] - 101s 108ms/step - loss: 1.6838 - acc: 0.6259\n","Epoch 12/30\n","938/938 [==============================] - 103s 110ms/step - loss: 1.6554 - acc: 0.6311\n","Epoch 13/30\n","938/938 [==============================] - 102s 108ms/step - loss: 1.6271 - acc: 0.6362\n","Epoch 14/30\n","938/938 [==============================] - 101s 107ms/step - loss: 1.5999 - acc: 0.6408\n","Epoch 15/30\n","938/938 [==============================] - 102s 109ms/step - loss: 1.5735 - acc: 0.6455\n","Epoch 16/30\n","938/938 [==============================] - 102s 109ms/step - loss: 1.5468 - acc: 0.6505\n","Epoch 17/30\n","938/938 [==============================] - 102s 109ms/step - loss: 1.5210 - acc: 0.6558\n","Epoch 18/30\n","938/938 [==============================] - 102s 109ms/step - loss: 1.4956 - acc: 0.6609\n","Epoch 19/30\n","938/938 [==============================] - 102s 109ms/step - loss: 1.4708 - acc: 0.6659\n","Epoch 20/30\n","938/938 [==============================] - 100s 107ms/step - loss: 1.4456 - acc: 0.6710\n","Epoch 21/30\n","938/938 [==============================] - 101s 107ms/step - loss: 1.4217 - acc: 0.6763\n","Epoch 22/30\n","938/938 [==============================] - 101s 107ms/step - loss: 1.3981 - acc: 0.6809\n","Epoch 23/30\n","938/938 [==============================] - 101s 107ms/step - loss: 1.3740 - acc: 0.6862\n","Epoch 24/30\n","938/938 [==============================] - 101s 107ms/step - loss: 1.3513 - acc: 0.6907\n","Epoch 25/30\n","938/938 [==============================] - 101s 108ms/step - loss: 1.3287 - acc: 0.6950\n","Epoch 26/30\n","938/938 [==============================] - 100s 106ms/step - loss: 1.3057 - acc: 0.7007\n","Epoch 27/30\n","938/938 [==============================] - 100s 107ms/step - loss: 1.2848 - acc: 0.7047\n","Epoch 28/30\n","938/938 [==============================] - 101s 108ms/step - loss: 1.2628 - acc: 0.7101\n","Epoch 29/30\n","938/938 [==============================] - 101s 107ms/step - loss: 1.2418 - acc: 0.7149\n","Epoch 30/30\n","938/938 [==============================] - 99s 106ms/step - loss: 1.2217 - acc: 0.7191\n"]},{"data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x792d0cb3c910>"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["model.fit([encoder_inp, decoder_inp],decoder_final_output,epochs=30)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T07:55:02.353714Z","iopub.status.busy":"2023-12-09T07:55:02.353198Z","iopub.status.idle":"2023-12-09T07:55:03.051032Z","shell.execute_reply":"2023-12-09T07:55:03.050208Z","shell.execute_reply.started":"2023-12-09T07:55:02.353680Z"},"trusted":true},"outputs":[],"source":["\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input\n","\n","\n","enc_model = Model([enc_inp], enc_states)\n","\n","\n","\n","# decoder Model\n","decoder_state_input_h = Input(shape=(400,))\n","decoder_state_input_c = Input(shape=(400,))\n","\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","\n","decoder_outputs, state_h, state_c = dec_lstm(dec_embed , \n","                                    initial_state=decoder_states_inputs)\n","\n","\n","decoder_states = [state_h, state_c]\n","\n","\n","dec_model = Model([dec_inp]+ decoder_states_inputs,\n","                                      [decoder_outputs]+ decoder_states)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-09T07:55:09.899372Z","iopub.status.busy":"2023-12-09T07:55:09.899075Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Using TensorFlow backend.\n"]},{"name":"stdout","output_type":"stream","text":["##########################################\n","#       start chatting ver. 1.0          #\n","##########################################\n"]},{"name":"stdout","output_type":"stream","text":["you :  hi how are you\n"]},{"name":"stdout","output_type":"stream","text":["chatbot attention :  i am sorry \n","==============================================\n"]},{"name":"stdout","output_type":"stream","text":["you :  hey\n"]},{"name":"stdout","output_type":"stream","text":["chatbot attention :  hey \n","==============================================\n"]},{"name":"stdout","output_type":"stream","text":["you :  whats up\n"]},{"name":"stdout","output_type":"stream","text":["chatbot attention :  i am sorry i am sorry i am sorry i am \n","==============================================\n"]},{"name":"stdout","output_type":"stream","text":["you :  hi\n"]},{"name":"stdout","output_type":"stream","text":["chatbot attention :  hi \n","==============================================\n"]},{"name":"stdout","output_type":"stream","text":["you :  how was you day\n"]},{"name":"stdout","output_type":"stream","text":["chatbot attention :  i am fine i am not \n","==============================================\n"]},{"name":"stdout","output_type":"stream","text":["you :  I think i can help you\n"]},{"name":"stdout","output_type":"stream","text":["chatbot attention :  you are not okay \n","==============================================\n"]},{"name":"stdout","output_type":"stream","text":["you :  fuck you\n"]},{"name":"stdout","output_type":"stream","text":["chatbot attention :  you know what i am talking about \n","==============================================\n"]},{"name":"stdout","output_type":"stream","text":["you :  Nah\n"]},{"name":"stdout","output_type":"stream","text":["chatbot attention :  i am sorry \n","==============================================\n"]},{"name":"stdout","output_type":"stream","text":["you :  Go kill your self\n"]},{"name":"stdout","output_type":"stream","text":["chatbot attention :  you are not <OUT> \n","==============================================\n"]}],"source":["import numpy as np\n","\n","\n","from keras.preprocessing.sequence import pad_sequences\n","print(\"##########################################\")\n","print(\"#       start chatting ver. 1.0          #\")\n","print(\"##########################################\")\n","\n","\n","prepro1 = \"\"\n","while prepro1 != 'q':\n","    prepro1  = input(\"you : \")\n","    ## prepro1 = \"Hello\"\n","\n","    prepro1 = clean_text(prepro1)\n","    ## prepro1 = \"hello\"\n","\n","    prepro = [prepro1]\n","    ## prepro1 = [\"hello\"]\n","\n","    txt = []\n","    for x in prepro:\n","        # x = \"hello\"\n","        lst = []\n","        for y in x.split():\n","            ## y = \"hello\"\n","            try:\n","                lst.append(vocab[y])\n","                ## vocab['hello'] = 454\n","            except:\n","                lst.append(vocab['<OUT>'])\n","        txt.append(lst)\n","\n","    ## txt = [[454]]\n","    txt = pad_sequences(txt, 13, padding='post')\n","\n","    ## txt = [[454,0,0,0,.........13]]\n","\n","    stat = enc_model.predict( txt )\n","\n","    empty_target_seq = np.zeros( ( 1 , 1) )\n","     ##   empty_target_seq = [0]\n","\n","\n","    empty_target_seq[0, 0] = vocab['<SOS>']\n","    ##    empty_target_seq = [255]\n","\n","    stop_condition = False\n","    decoded_translation = ''\n","\n","    while not stop_condition :\n","\n","        dec_outputs , h, c= dec_model.predict([ empty_target_seq] + stat )\n","        decoder_concat_input = dense(dec_outputs)\n","        ## decoder_concat_input = [0.1, 0.2, .4, .0, ...............]\n","\n","        sampled_word_index = np.argmax( decoder_concat_input[0, -1, :] )\n","        ## sampled_word_index = [2]\n","\n","        sampled_word = inv_vocab[sampled_word_index] + ' '\n","\n","        ## inv_vocab[2] = 'hi'\n","        ## sampled_word = 'hi '\n","\n","        if sampled_word != '<EOS> ':\n","            decoded_translation += sampled_word  \n","\n","        if sampled_word == '<EOS> ' or len(decoded_translation.split()) > 13:\n","            stop_condition = True \n","\n","        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n","        empty_target_seq[ 0 , 0 ] = sampled_word_index\n","        ## <SOS> - > hi\n","        ## hi --> <EOS>\n","        stat = [h, c]  \n","\n","    print(\"Syra \", decoded_translation )\n","    print(\"==============================================\")  "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":9714,"sourceId":13808,"sourceType":"datasetVersion"},{"datasetId":13433,"sourceId":18178,"sourceType":"datasetVersion"}],"dockerImageVersionId":29962,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}
